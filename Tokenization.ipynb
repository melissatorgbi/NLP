{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melissatorgbi/NLP/blob/main/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weQU-StfuRzw"
      },
      "source": [
        "# Week 1: Use of Tokenization in Practice\n",
        "\n",
        "&copy;2022, Ekaterina Kochmar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZwK8uSCuRzy"
      },
      "source": [
        "Your task in this activity is to:\n",
        "\n",
        "- Implement a simple word tokenization algorithm based on regular expressions.\n",
        "- Use one of the available tokenizers from NLTK and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7jqFdV3uRzz"
      },
      "source": [
        "## Task 1: Import data\n",
        "\n",
        "Import data from NLTK (see http://www.nltk.org/book_1ed/ch02.html):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc2QF0ltuRz0"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('webtext')\n",
        "from nltk.corpus import webtext\n",
        "\n",
        "print(webtext.raw(\"pirates.txt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr16tw4kuRz2"
      },
      "source": [
        "Extract the first sentence as an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLX24gwJuRz3"
      },
      "outputs": [],
      "source": [
        "sentence = #take the webtext.raw(\"pirates.txt\") as above,\n",
        "           #split it by newline \\n, and extract the first sentence (i.e., at position 0)\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lULu8VGcuRz4"
      },
      "source": [
        "## Task 2: Implement a simple tokenization algorithm\n",
        "\n",
        "Split the sentence by whitespace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yixTPm0uRz5"
      },
      "outputs": [],
      "source": [
        "print(# split sentence by whitespace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMmcWPiYuRz6"
      },
      "source": [
        "Do you see any problems with this approach?\n",
        "\n",
        "Let's try pattern-matching:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS6V_3WDuRz6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "tokens = re.split(# define a pattern: e.g., r\"([-])+\" would split by \"-\" only; add other punctuation marks\n",
        "         , sentence)\n",
        "\n",
        "tokenized = [x for x in tokens if x != '' and x not in '- \\t\\n.,;:!?[]']\n",
        "print(tokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about *Mr. Sherwood said reaction to Sea Containers’ proposal has been “very positive.”*?"
      ],
      "metadata": {
        "id": "OluSjbQ4uwxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply to the sentence \"Mr. Sherwood said reaction to Sea Containers' proposal has been \\\"very positive.\\\"\""
      ],
      "metadata": {
        "id": "UEByZTcJuzku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eboYrTlXuRz7"
      },
      "source": [
        "Does this solve all the problems? Do you see any challenges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A18j2zOUuRz8"
      },
      "source": [
        "## Task 3: Apply an out-of-the-box algorithm\n",
        "\n",
        "Use NLTK's tokenizer (see https://www.nltk.org/book/ch03.html):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkoVBDDLuRz8"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokens = # tokenize sentence using word_tokenize\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNVA9Q7AuRz9"
      },
      "source": [
        "Let's convert all words to lower case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTwhKKTauRz-"
      },
      "outputs": [],
      "source": [
        "words = [w.lower() for w in tokens]\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQT3UhdOuRz-"
      },
      "source": [
        "Finally, sort the words in alphabetical order:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxhsJc9puRz-"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(words))\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGrgH7xuRz_"
      },
      "source": [
        "## Task 4: Apply to other sentences\n",
        "\n",
        "This is an open-ended task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eHui33suRz_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}